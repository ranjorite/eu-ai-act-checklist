import type { QuestionnaireItem, DocumentationItem } from './types';

export const QUESTIONNAIRE_DATA: QuestionnaireItem[] = [
  { id: 1, topic: 'Goals', question: 'Are the goals, scope, and methods of the AI system clearly defined and documented?', nist: 'MAP 1.3 MAP 2.1 MAP 3.3', article: '' },
  { id: 2, topic: 'Positive Impacts', question: 'Have the benefits and potential positive impacts of the AI system been identified, including their likelihood and magnitude?', nist: 'MAP 1.1 MAP 3.1 MAP 5.1 GOV 4.2', article: '' },
  { id: 3, topic: 'Business Value', question: 'Is the business value of the AI system clearly identified and documented?', nist: 'MAP 1.4 MAP 3.1', article: '' },
  { id: 4, topic: 'Negative Impacts', question: 'Have the possible negative impacts of the AI system, including their likelihood and magnitude, been identified and assessed?', nist: 'MAP 5.1 GOV 4.2', article: '' },
  { id: 5, topic: 'Costs of Malfunction', question: 'Are the potential costs of malfunctions, including non-monetary costs like decreased trustworthiness, identified and documented?', nist: 'GOV 3.2', article: '' },
  { id: 6, topic: 'Unexpected Impacts', question: 'Are processes in place to integrate input about unexpected impacts of the AI system?', nist: 'GOV 5.2', article: '' },
  { id: 7, topic: 'Methods and Tools', question: 'Are the methods and tools used for mapping the impacts of the AI system identified and documented?', nist: 'MAP 2.3 MAP 4.1', article: '' },
  { id: 8, topic: 'Input Diversity', question: 'Are diverse stakeholders, including those with different skills and demographic backgrounds, involved in the impact mapping process?', nist: 'MAP 1.2 GOV 3.1 GOV 5.1 GOV 5.2', article: '' },
  { id: 9, topic: 'Human Oversight', question: 'Are human oversight processes for the AI system clearly identified and documented?', nist: 'GOV 3.2 MAP 3.5', article: 'Provider Article 14' },
  { id: 10, topic: 'Standards', question: 'Have relevant technical standards and certifications for the AI system been identified and documented?', nist: 'MAP 1.6 MAP 3.4', article: 'Provider Article 17.1e' },
  { id: 11, topic: 'Legal', question: 'Are the relevant legal requirements for the AI system identified and documented?', nist: 'GOV 1.1', article: 'Provider Article 17.1a' },
  { id: 12, topic: 'Policies', question: 'Are the policies and guidelines regarding AI ethics documented?', nist: 'GOV 1.2 GOV 1.4', article: 'Provider Article 10' },
  { id: 13, topic: 'Roles', question: 'Are roles, responsibilities, and lines of communication for AI risk management well-defined and documented?', nist: 'GOV 2.1', article: 'Provider Article 17.1m' },
  { id: 14, topic: 'Training', question: 'Is AI ethics training provided to relevant personnel, and is this training documented?', nist: 'GOV 2.2', article: 'Provider & Deployer Articles 26.2.4' },
  { id: 15, topic: 'Critical Thinking', question: 'Are practices to foster critical thinking about AI risks implemented and documented?', nist: 'GOV 4.1', article: '' },
  { id: 16, topic: 'Leadership', question: 'Does executive leadership take responsibility for decisions related to AI risks, and is this responsibility documented?', nist: 'GOV 2.3', article: '' },
  { id: 17, topic: 'Strategy', question: 'Is the strategy for measuring the impacts of the AI system periodically re-evaluated, including how unexpected impacts are monitored?', nist: 'MEA 1.1 MEA 3.1 MEA 3.2 MAP 2.3', article: 'Provider Articles 9 10 17 72; if GPAI with systemic risk' },
  { id: 18, topic: 'Methods', question: 'Are there clear methods and tools in place for measuring the impacts of the AI system, including specific metrics and datasets?', nist: 'MEA 1.2 MEA 2.1 MEA 3.1 MEA 3.2 MAP 2.3', article: 'Provider Articles 9.7 17.1d 60' },
  { id: 19, topic: 'Effectiveness', question: 'Is the effectiveness of the AI system\'s measurement processes regularly evaluated and documented?', nist: 'MEA 1.2 MEA 2.13', article: '' },
  { id: 20, topic: 'Performance', question: 'Is the performance of the AI system regularly evaluated in conditions similar to deployment, and is this evaluation documented?', nist: 'MEA 2.3', article: 'Provider Articles 9 17' },
  { id: 21, topic: 'Bias and Fairness', question: 'Are bias and fairness issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.11', article: 'Provider Articles 9 17' },
  { id: 22, topic: 'Privacy', question: 'Are privacy issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.10', article: 'Provider Articles 9 17' },
  { id: 23, topic: 'Environmental', question: 'Are environmental impacts related to the AI system regularly evaluated and documented?', nist: 'MEA 2.12', article: 'Provider Articles 9 17' },
  { id: 24, topic: 'Explainability', question: 'Are explainability issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.9', article: 'Provider Articles 9 17' },
  { id: 25, topic: 'Third-party', question: 'Are third-party issues, such as IP infringement, regularly evaluated and documented?', nist: 'MEA 1.1 GOV 6.1', article: 'Provider Articles 9 17' },
  { id: 26, topic: 'Transparency and accountability', question: 'Are transparency and accountability issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.8', article: 'Provider Articles 9 17' },
  { id: 27, topic: 'Security', question: 'Are security and resilience issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.7', article: 'Provider Articles 9 17' },
  { id: 28, topic: 'Safety', question: 'Are safety issues related to the AI system regularly evaluated and documented?', nist: 'MEA 2.6', article: 'Provider Articles 9 17' },
  { id: 29, topic: 'Limitations and Oversight', question: 'Is information about the AI system’s limitations and options for human oversight well-documented to assist decision-makers?', nist: 'GOV 1.4 MAP 2.2', article: 'Providers Article 13' },
  { id: 30, topic: 'Risk Controls', question: 'Are system risk controls, including those in third-party components, documented?', nist: 'GOV 1.4 MAP 2.2', article: 'Providers Article 17.1' },
  { id: 31, topic: 'Model Explanation', question: 'Is the AI model explained sufficiently to ensure responsible use, and is this explanation documented?', nist: 'GOV 1.4 MEA 2.9', article: 'Providers Article 13' },
  { id: 32, topic: 'Repository', question: 'Is information about the AI system inventoried in a repository of the organization’s AI systems?', nist: 'GOV 1.6', article: '' },
  { id: 33, topic: 'User Transparency', question: 'Is AI-generated content, including user interactions and deep fakes, appropriately marked and documented?', nist: '', article: 'Article 50' },
  { id: 34, topic: 'Data Transparency', question: 'Is a publicly available summary of the GPAI model’s training data published using the EU AI Office template?', nist: '', article: 'GPAI Article 53.d' },
  { id: 35, topic: 'Plan', question: 'Does the organization have a plan to respond to risks caused by the AI system, including defining risk tolerance and deciding on risk mitigation, avoidance, or acceptance?', nist: 'GOV 1.3 GOV 1.4 MAP 1.5 MAN 1.3 MAN 2.1 GOV 1.3 MAN 1.2', article: 'Provider Articles 9 17; if GPAI with systemic risk Article' },
  { id: 36, topic: 'Prioritization', question: 'Are responses to AI system risks prioritized based on impact, likelihood, available resources, and the organization’s risk tolerance?', nist: 'MAN 1.3 MAN 2.1', article: '' },
  { id: 37, topic: 'Residual Risks', question: 'Are residual risks of the AI system, including risks to buyers and users, identified and documented?', nist: 'MAN 1.4', article: '' },
  { id: 38, topic: 'Unexpected Risks', question: 'Is there a plan in place to address unexpected risks related to the AI system as they arise?', nist: 'GOV 1.4 MAN 2.1 MAN 2.3', article: '' },
  { id: 39, topic: 'Vulnerable Groups', question: 'Does the organization’s risk management plan give special consideration to potential adverse impacts on persons under 18 and other vulnerable groups?', nist: '', article: 'Provider Article 9.9' },
  { id: 40, topic: 'Meets Objectives', question: 'Does the organization proactively evaluate whether the AI system meets its stated objectives, and should its development or deployment proceed?', nist: 'MAN 1.1 GOV 1.5', article: 'Provider Articles 9 17; if GPAI with systemic risk Article' },
  { id: 41, topic: 'Bias & Fairness', question: 'Does the AI system\'s bias and fairness performance meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MAN 4.2 MEA 2.11', article: 'Provider Articles 9 10 17' },
  { id: 42, topic: 'Privacy', question: 'Does the AI system\'s privacy performance meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.10 MAN 4.2', article: 'Provider Articles 9 10 17' },
  { id: 43, topic: 'Environment', question: 'Does the AI system\'s environmental performance meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.12 MAN 4.2', article: 'Provider Articles 9 17' },
  { id: 44, topic: 'Transparency & Accountability', question: 'Does the AI system\'s transparency and accountability meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.8 MAN 4.2', article: 'Provider Articles 9 17' },
  { id: 45, topic: 'Security', question: 'Does the AI system\'s security and resilience meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.7 MAN 4.2', article: 'Provider Articles 9 17' },
  { id: 46, topic: 'Explainability', question: 'Does the AI system\'s explainability performance meet the organization\'s standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.9 MAN 4.2', article: 'Provider Articles 9' },
  { id: 47, topic: 'Third Party', question: 'Do the AI system\'s third-party impacts, such as IP infringement, meet the organization\'s standards, and are they regularly monitored and documented?', nist: 'MAN 3.1 GOV 6.1 MAN 1.3', article: 'Provider Articles 9 17' },
  { id: 48, topic: 'Human Oversight', question: 'Are processes for human oversight related to the AI system implemented, and are these processes documented?', nist: 'GOV 3.2 MAP 3.5 MAN 1.3', article: 'Provider & Deployer Articles 9 14 17 26.2' },
  { id: 49, topic: 'Appeal', question: 'Are processes for appeal related to the AI system implemented, and are these processes documented?', nist: 'MAN 4.1', article: '' },
  { id: 50, topic: 'End of Life', question: 'Does the organization maintain end-of-life mechanisms to supersede, disengage, or deactivate the AI system if its performance or outcomes are inconsistent with the intended use?', nist: 'GOV 1.7', article: 'Provider Articles 9 17' },
  { id: 51, topic: 'Safety', question: 'Does the AI system meet the organization\'s safety standards, and is this regularly monitored and documented?', nist: 'MAN 1.3 MEA 2.6 MAN 4.2', article: 'Provider Articles 9 17' },
  { id: 52, topic: 'Other Risks', question: 'Are all other risks prioritized in the organization\'s risk management plans related to this AI system addressed through measurable activities, and are these activities documented?', nist: 'MAN', article: '' },
];


export const DOCUMENTATION_DATA: DocumentationItem[] = [
  // Data Scope
  { id: 'd1', scope: 'Data', requirements: 'Data provenance', target: 'Authorities and conformity assessors', controlName: 'Data origin', documentation: 'Document the source(s) of data collection (e.g., Internet, private databases, third-party public datasets).', articles: '10, 11' },
  { id: 'd2', scope: 'Data', requirements: 'Dataset scope', target: 'Users, Authorities and conformity assessors', controlName: 'Data type and scope', documentation: 'Document the type of data (e.g., numerical, categorical, text, image) and its scope (e.g., sales data, personal data, medical data for a specific population), including any data gaps or deficiencies (e.g., insufficient data, inappropriate granularity).', articles: '10, 11, 13' },
  { id: 'd3', scope: 'Data', requirements: 'Data collection', target: 'Authorities and conformity assessors', controlName: 'Data collection methods', documentation: 'Document the method of data collection (e.g., web crawling, querying a private database), and describe aggregation techniques if data comes from multiple sources.', articles: '10, 11' },
  { id: 'd4', scope: 'Data', requirements: 'Data preparation', target: 'Users', controlName: 'Data format and splitting', documentation: 'Document the data format and the division into training, testing, and validation sets, with details of their individual characteristics.', articles: '10, 13' },
  { id: 'd5', scope: 'Data', requirements: 'Data preparation', target: 'Authorities and conformity assessors', controlName: 'Data preparation and processing', documentation: 'Document the data preparation and processing steps, such as annotation, labeling, cleaning, and enrichment.', articles: '10, 11' },
  { id: 'd6', scope: 'Data', requirements: 'Data correctness', target: 'Authorities and conformity assessors', controlName: 'Data quality assessment', documentation: 'Document the analysis of dataset quality using concrete metrics (e.g., image resolution, missing values, outliers, noise levels).', articles: '10, 11' },
  { id: 'd7', scope: 'Data', requirements: 'Data representativeness', target: 'Users, Authorities and conformity assessors', controlName: 'Data relevance and representativeness', documentation: 'Document the relevance and representativeness of the data with measures and metrics regarding the target population and the system’s intended context.', articles: '10, 11, 13' },
  { id: 'd8', scope: 'Data', requirements: 'Data privacy', target: 'Authorities and conformity assessors', controlName: 'Data privacy and safeguards', documentation: 'Document the privacy measures implemented to safeguard individuals’ rights (e.g., pseudonymization, encryption, anonymization, aggregation).', articles: '10, 11, 13' },
  
  // Systems Scope
  { id: 'd9', scope: 'Systems', requirements: 'Purpose', target: 'Users, Authorities and conformity assessors', controlName: 'AI system purpose and misuse', documentation: 'Document the intended purpose of the AI system and any reasonably foreseeable misuse scenarios.', articles: '8, 9, 11, 13' },
  { id: 'd10', scope: 'Systems', requirements: 'Risks', target: 'Users', controlName: 'Risk identification', documentation: 'Document the potential risks associated with the AI system, including those related to health, safety, and fundamental rights.', articles: '9, 13' },
  { id: 'd11', scope: 'Systems', requirements: 'Risks', target: 'Authorities and conformity assessors', controlName: 'Risk mitigation and residual risks', documentation: 'Document the design features and mitigations adopted to address identified risks, as well as any remaining residual risks.', articles: '9, 11' },
  { id: 'd12', scope: 'Systems', requirements: 'Interpretation', target: 'Users', controlName: 'System output interpretation', documentation: 'Document the information needed to ensure users can correctly interpret the system’s outputs and use them appropriately.', articles: '13' },
  { id: 'd13', scope: 'Systems', requirements: 'Interpretation', target: 'Authorities and conformity assessors', controlName: 'Interpretability measures', documentation: 'Document the measures implemented to enhance the interpretability of the system’s outputs.', articles: '11, 13' },
  { id: 'd14', scope: 'Systems', requirements: 'Human oversight', target: 'Users', controlName: 'Human oversight mechanisms', documentation: 'Document the human oversight measures in place to monitor the system, understand its decision-making, detect anomalies, and prevent over-reliance.', articles: '11, 14' },
  { id: 'd15', scope: 'Systems', requirements: 'Human oversight', target: 'Authorities and conformity assessors', controlName: 'Oversight assessment', documentation: 'Document the assessment of the human oversight measures and their effectiveness.', articles: '11, 14' },
  { id: 'd16', scope: 'Systems', requirements: 'Architecture', target: 'Authorities and conformity assessors', controlName: 'AI system architecture', documentation: 'Document the AI system architecture, including the type of algorithm/model, processing steps, software components, and computational resources used in training, testing, validation, and operation.', articles: '11' },
  { id: 'd17', scope: 'Systems', requirements: 'Development', target: 'Authorities and conformity assessors', controlName: 'Development methods and components', documentation: 'Document the methods and processes used for AI system development, including any pretrained models, tools, or components utilized.', articles: '11' },
  { id: 'd18', scope: 'Systems', requirements: 'Training', target: 'Authorities and conformity assessors', controlName: 'Training process and parameters', documentation: 'Document how the AI system was trained, including optimization targets, objective functions, relevant parameters, trade-offs, training techniques, and assumptions made.', articles: '11' },
  { id: 'd19', scope: 'Systems', requirements: 'Accuracy', target: 'Users, Authorities and conformity assessors', controlName: 'Accuracy levels', documentation: 'Document the achieved and expected accuracy levels, particularly for specific individuals or groups targeted by the system.', articles: '13, 15' },
  { id: 'd20', scope: 'Systems', requirements: 'Robustness', target: 'Users', controlName: 'Performance limitations', documentation: 'Document the situations and circumstances that may impair system performance, including potential sources of errors, faults, or inconsistencies.', articles: '13' },
  { id: 'd21', scope: 'Systems', requirements: 'Robustness', target: 'Authorities and conformity assessors', controlName: 'Robustness and resilience measures', documentation: 'Document the robustness and resilience measures adopted, whether algorithmic, system-level, or through fail-safe mechanisms or redundancy.', articles: '11, 15' },
  { id: 'd22', scope: 'Systems', requirements: 'Cybersecurity', target: 'Users, Authorities and conformity assessors', controlName: 'Cybersecurity measures', documentation: 'Document the cybersecurity measures taken to protect the AI system from specific threats (e.g., adversarial attacks, data poisoning), including metrics and evaluation results.', articles: '13, 15' },
  { id: 'd23', scope: 'Systems', requirements: 'Testing', target: 'Authorities and conformity assessors', controlName: 'Testing and verification protocol', documentation: 'Document the testing and verification protocol, including logs showing accuracy, robustness, and cybersecurity levels with metrics and thresholds.', articles: '11, 15' },
  { id: 'd24', scope: 'Systems', requirements: 'Changes', target: 'Users', controlName: 'Post-market system changes', documentation: 'Document any anticipated changes to the AI system after deployment (e.g., continued learning during operation).', articles: '13' },
  { id: 'd25', scope: 'Systems', requirements: 'Changes', target: 'Authorities and conformity assessors', controlName: 'Performance maintenance post-changes', documentation: 'Document the measures in place to maintain system performance after changes, considering potential feedback loops.', articles: '11, 15' },
  { id: 'd26', scope: 'Systems', requirements: 'System aspects', target: 'Authorities and conformity assessors', controlName: 'System-level integration', documentation: 'Document the system-level aspects beyond the AI model, including integration with hardware, firmware, and interactions with non-AI subsystems.', articles: '11' },
];